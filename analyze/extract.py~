from sklearn.feature_extraction import text
from sklearn import decomposition
from collections import Counter
import redis, sys, json, pickle, numpy, re, time
from pymongo import Connection

n_samples = 5000
n_features = 1000
n_topics = 10
n_top_words = 20

mongo = Connection('localhost', 27017).ml.data

db = redis.StrictRedis(host='localhost', port=6379, db=0)
keyword = sys.argv[1]
interval = (float(sys.argv[2])*10**6, float(sys.argv[3])*10**6)
ids = db.zrangebyscore('positive:'+keyword,interval[0],interval[1])
data = []
tweet_urls = []
ids = ids[:5]
for i in ids:
	tweet = json.loads(db.hget('tweets:'+keyword, i))
	tweet_time = time.mktime(time.strptime(tweet[u'created_at'],"%a %b %d %H:%M:%S +0000 %Y"))
	data = { 'time': tweet_time, 'stream_time' : tweet_time, 'data': tweet }
	mongo.insert(data)
